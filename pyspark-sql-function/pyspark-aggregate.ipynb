{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c4534f7",
   "metadata": {},
   "source": [
    "https://sparkbyexamples.com/pyspark/pyspark-aggregate-functions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b9a846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import approx_count_distinct, collect_list\n",
    "from pyspark.sql.functions import collect_set, sum, avg, max, countDistinct, count\n",
    "from pyspark.sql.functions import first, last, kurtosis, min, mean, skewness\n",
    "from pyspark.sql.functions import stddev, stddev_samp, stddev_pop, sumDistinct\n",
    "from pyspark.sql.functions import variance, var_samp, var_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32012b1e",
   "metadata": {},
   "source": [
    "PySpark provides built-in standard Aggregate functions defines in DataFrame API, these come in handy when we need to make aggregate operations on DataFrame columns. Aggregate functions operate on a group of rows and calculate a single return value for every group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa74280d",
   "metadata": {},
   "source": [
    "All these aggregate functions accept input as, Column type or column name in a string and several other arguments based on the function and return Column type.\n",
    "\n",
    "When possible try to leverage standard library as they are little bit more compile-time safety, handles null and perform better when compared to UDF’s. If your application is critical on performance try to avoid using custom UDF at all costs as these are not guarantee on performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30723f6e",
   "metadata": {},
   "source": [
    "# PySpark Aggregate Functions\n",
    "PySpark SQL Aggregate functions are grouped as “agg_funcs” in Pyspark. Below is a list of functions defined under this group.\n",
    "\n",
    "- approx_count_distinct\n",
    "- avg\n",
    "- collect_list\n",
    "- collect_set\n",
    "- countDistinct\n",
    "- count\n",
    "- grouping\n",
    "- first\n",
    "- last\n",
    "- kurtosis\n",
    "- max\n",
    "- min\n",
    "- mean\n",
    "- skewness\n",
    "- stddev\n",
    "- stddev_samp\n",
    "- stddev_pop\n",
    "- sum\n",
    "- sumDistinct\n",
    "- variance, var_samp, var_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f3a66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|James        |Sales     |3000  |\n",
      "|Michael      |Sales     |4600  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Maria        |Finance   |3000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Scott        |Finance   |3300  |\n",
      "|Jen          |Finance   |3900  |\n",
      "|Jeff         |Marketing |3000  |\n",
      "|Kumar        |Marketing |2000  |\n",
      "|Saif         |Sales     |4100  |\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simpleData = [(\"James\", \"Sales\", 3000), (\"Michael\", \"Sales\", 4600),\n",
    "              (\"Robert\", \"Sales\", 4100), (\"Maria\", \"Finance\", 3000),\n",
    "              (\"James\", \"Sales\", 3000), (\"Scott\", \"Finance\", 3300),\n",
    "              (\"Jen\", \"Finance\", 3900), (\"Jeff\", \"Marketing\", 3000),\n",
    "              (\"Kumar\", \"Marketing\", 2000), (\"Saif\", \"Sales\", 4100)]\n",
    "schema = [\"employee_name\", \"department\", \"salary\"]\n",
    "\n",
    "df = spark.createDataFrame(data=simpleData, schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05793aaf",
   "metadata": {},
   "source": [
    "## approx_count_distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a119922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(approx_count_distinct(\"salary\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195c4ee7",
   "metadata": {},
   "source": [
    "## avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81b19448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3400.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(avg(\"salary\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfea641",
   "metadata": {},
   "source": [
    "## collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09139470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|collect_list(salary)                                        |\n",
      "+------------------------------------------------------------+\n",
      "|[3000, 4600, 4100, 3000, 3000, 3300, 3900, 3000, 2000, 4100]|\n",
      "+------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(collect_list(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6901296d",
   "metadata": {},
   "source": [
    "## collect_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a42cbbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+\n",
      "|collect_set(salary)                 |\n",
      "+------------------------------------+\n",
      "|[4600, 3000, 3900, 4100, 3300, 2000]|\n",
      "+------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(collect_set(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754e517f",
   "metadata": {},
   "source": [
    "## countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fdbac82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|count(DISTINCT department, salary)|\n",
      "+----------------------------------+\n",
      "|8                                 |\n",
      "+----------------------------------+\n",
      "\n",
      "Distinct Count of Department &amp; Salary: 8\n"
     ]
    }
   ],
   "source": [
    "df2 = df.select(countDistinct(\"department\", \"salary\"))\n",
    "df2.show(truncate=False)\n",
    "print(\"Distinct Count of Department &amp; Salary: \" + str(df2.collect()[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68053bfd",
   "metadata": {},
   "source": [
    "## count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59d3a5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(count(salary)=10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(count(\"salary\")).collect()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f833f70c",
   "metadata": {},
   "source": [
    "## first and last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "948e3bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|first(salary)|\n",
      "+-------------+\n",
      "|3000         |\n",
      "+-------------+\n",
      "\n",
      "+------------+\n",
      "|last(salary)|\n",
      "+------------+\n",
      "|4100        |\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(first(\"salary\")).show(truncate=False)\n",
    "df.select(last(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f84b10",
   "metadata": {},
   "source": [
    "## kurtosis\n",
    "kurtosis() function returns the kurtosis of the values in a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fb45f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|kurtosis(salary)   |\n",
      "+-------------------+\n",
      "|-0.6467803030303032|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(kurtosis(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd50f730",
   "metadata": {},
   "source": [
    "## min max sum sumDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a724dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|max(salary)|\n",
      "+-----------+\n",
      "|4600       |\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|min(salary)|\n",
      "+-----------+\n",
      "|2000       |\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|avg(salary)|\n",
      "+-----------+\n",
      "|3400.0     |\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|sum(salary)|\n",
      "+-----------+\n",
      "|34000      |\n",
      "+-----------+\n",
      "\n",
      "+--------------------+\n",
      "|sum(DISTINCT salary)|\n",
      "+--------------------+\n",
      "|20900               |\n",
      "+--------------------+\n",
      "\n",
      "+-----------------+-----------------+---------------+\n",
      "|var_samp(salary) |var_samp(salary) |var_pop(salary)|\n",
      "+-----------------+-----------------+---------------+\n",
      "|586666.6666666666|586666.6666666666|528000.0       |\n",
      "+-----------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(max(\"salary\")).show(truncate=False)\n",
    "df.select(min(\"salary\")).show(truncate=False)\n",
    "df.select(mean(\"salary\")).show(truncate=False)\n",
    "df.select(sum(\"salary\")).show(truncate=False)\n",
    "df.select(sumDistinct(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d82abbf",
   "metadata": {},
   "source": [
    "## variance\n",
    "\n",
    "- variance() alias for var_samp\n",
    "- var_samp() function returns the unbiased variance of the values in a column.\n",
    "- var_pop() function returns the population variance of the values in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29b9855a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+---------------+\n",
      "|var_samp(salary) |var_samp(salary) |var_pop(salary)|\n",
      "+-----------------+-----------------+---------------+\n",
      "|586666.6666666666|586666.6666666666|528000.0       |\n",
      "+-----------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(variance(\"salary\"),var_samp(\"salary\"),var_pop(\"salary\")) \\\n",
    "  .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079ce59a",
   "metadata": {},
   "source": [
    "## skewness\n",
    "skewness() function returns the skewness of the values in a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0f9fdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|skewness(salary)    |\n",
      "+--------------------+\n",
      "|-0.12041791181069571|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(skewness(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b35c179",
   "metadata": {},
   "source": [
    "## stddev\n",
    "- stddev() alias for stddev_samp.\n",
    "- stddev_samp() function returns the sample standard deviation of values in a column.\n",
    "- stddev_pop() function returns the population standard deviation of the values in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "949eef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------------+\n",
      "|stddev_samp(salary)|stddev_samp(salary)|stddev_pop(salary)|\n",
      "+-------------------+-------------------+------------------+\n",
      "|765.9416862050705  |765.9416862050705  |726.636084983398  |\n",
      "+-------------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(stddev(\"salary\"), stddev_samp(\"salary\"), \\\n",
    "    stddev_pop(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82467799",
   "metadata": {},
   "source": [
    "```python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Jun 14 10:20:19 2020\n",
    "\n",
    "@author: prabha\n",
    "\"\"\"\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import approx_count_distinct,collect_list\n",
    "from pyspark.sql.functions import collect_set,sum,avg,max,countDistinct,count\n",
    "from pyspark.sql.functions import first, last, kurtosis, min, mean, skewness \n",
    "from pyspark.sql.functions import stddev, stddev_samp, stddev_pop, sumDistinct\n",
    "from pyspark.sql.functions import variance,var_samp,  var_pop\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "simpleData = [(\"James\", \"Sales\", 3000),\n",
    "    (\"Michael\", \"Sales\", 4600),\n",
    "    (\"Robert\", \"Sales\", 4100),\n",
    "    (\"Maria\", \"Finance\", 3000),\n",
    "    (\"James\", \"Sales\", 3000),\n",
    "    (\"Scott\", \"Finance\", 3300),\n",
    "    (\"Jen\", \"Finance\", 3900),\n",
    "    (\"Jeff\", \"Marketing\", 3000),\n",
    "    (\"Kumar\", \"Marketing\", 2000),\n",
    "    (\"Saif\", \"Sales\", 4100)\n",
    "  ]\n",
    "schema = [\"employee_name\", \"department\", \"salary\"]\n",
    "  \n",
    "  \n",
    "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "print(\"approx_count_distinct: \" + \\\n",
    "      str(df.select(approx_count_distinct(\"salary\")).collect()[0][0]))\n",
    "\n",
    "print(\"avg: \" + str(df.select(avg(\"salary\")).collect()[0][0]))\n",
    "\n",
    "df.select(collect_list(\"salary\")).show(truncate=False)\n",
    "\n",
    "df.select(collect_set(\"salary\")).show(truncate=False)\n",
    "\n",
    "df2 = df.select(countDistinct(\"department\", \"salary\"))\n",
    "df2.show(truncate=False)\n",
    "print(\"Distinct Count of Department &amp; Salary: \"+str(df2.collect()[0][0]))\n",
    "\n",
    "print(\"count: \"+str(df.select(count(\"salary\")).collect()[0]))\n",
    "df.select(first(\"salary\")).show(truncate=False)\n",
    "df.select(last(\"salary\")).show(truncate=False)\n",
    "df.select(kurtosis(\"salary\")).show(truncate=False)\n",
    "df.select(max(\"salary\")).show(truncate=False)\n",
    "df.select(min(\"salary\")).show(truncate=False)\n",
    "df.select(mean(\"salary\")).show(truncate=False)\n",
    "df.select(skewness(\"salary\")).show(truncate=False)\n",
    "df.select(stddev(\"salary\"), stddev_samp(\"salary\"), \\\n",
    "    stddev_pop(\"salary\")).show(truncate=False)\n",
    "df.select(sum(\"salary\")).show(truncate=False)\n",
    "df.select(sumDistinct(\"salary\")).show(truncate=False)\n",
    "df.select(variance(\"salary\"),var_samp(\"salary\"),var_pop(\"salary\")) \\\n",
    "  .show(truncate=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d8e712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
